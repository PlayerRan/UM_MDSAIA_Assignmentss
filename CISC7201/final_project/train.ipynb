{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset path = E:\\Mycode\\UM_MDSAIA_Assignmentss\\CISC7201\\final_project\\processed_lianjia_data_filtered.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE: 3014607.752442997\n",
      "MLP Regressor MSE: 373817.82477807254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Define features and target variable\n",
    "df = pd.read_csv('E:\\\\Mycode\\\\UM_MDSAIA_Assignmentss\\\\CISC7201\\\\final_project\\\\processed_lianjia_data_filtered.csv')\n",
    "X = df.drop(columns=['price_per_sqm'])\n",
    "y = df['price_per_sqm']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "mlp_regressor = MLPRegressor(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the Decision Tree Regressor\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "y_pred_dt = dt_regressor.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "print(f'Decision Tree Regressor MSE: {mse_dt}')\n",
    "\n",
    "# Train the MLP Regressor\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_regressor.predict(X_test)\n",
    "mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
    "print(f'MLP Regressor MSE: {mse_mlp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 检查是否有可用的GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor MSE for price_per_sqm: 3014607.752442997\n",
      "MLP Regressor MSE for price_per_sqm: 373817.82477807254\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable for price_per_sqm prediction\n",
    "X_price = df.drop(columns=['price_per_sqm'])\n",
    "y_price = df['price_per_sqm']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_price, X_test_price, y_train_price, y_test_price = train_test_split(X_price, y_price, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "dt_regressor_price = DecisionTreeRegressor(random_state=42)\n",
    "mlp_regressor_price = MLPRegressor(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the Decision Tree Regressor\n",
    "dt_regressor_price.fit(X_train_price, y_train_price)\n",
    "y_pred_dt_price = dt_regressor_price.predict(X_test_price)\n",
    "mse_dt_price = mean_squared_error(y_test_price, y_pred_dt_price)\n",
    "print(f'Decision Tree Regressor MSE for price_per_sqm: {mse_dt_price}')\n",
    "\n",
    "# Train the MLP Regressor\n",
    "mlp_regressor_price.fit(X_train_price, y_train_price)\n",
    "y_pred_mlp_price = mlp_regressor_price.predict(X_test_price)\n",
    "mse_mlp_price = mean_squared_error(y_test_price, y_pred_mlp_price)\n",
    "print(f'MLP Regressor MSE for price_per_sqm: {mse_mlp_price}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure MLP Regressor MSE: 433872352.0\n",
      "Pure Random Forest Regressor MSE: 7041528.4241601275\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Initialize the MLP model, loss function, and optimizer\n",
    "mlp_model = MLP(X_train.shape[1])\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mlp_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the MLP model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    mlp_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = mlp_model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the MLP model\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_mlp_tensor = mlp_model(X_test_tensor)\n",
    "    mse_mlp = criterion(y_pred_mlp_tensor, y_test_tensor).item()\n",
    "print(f'Pure MLP Regressor MSE: {mse_mlp}')\n",
    "\n",
    "# Basic implementation of Random Forest\n",
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.trees = [DecisionTreeRegressor(max_depth=self.max_depth) for _ in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for tree in self.trees:\n",
    "            bootstrap_indices = np.random.choice(np.arange(X.shape[0]), size=X.shape[0], replace=True)\n",
    "            X_bootstrap = X[bootstrap_indices]\n",
    "            y_bootstrap = y[bootstrap_indices]\n",
    "            tree.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return np.mean(tree_preds, axis=0)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForest(n_estimators=100, max_depth=10)\n",
    "rf_model.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "y_pred_rf = rf_model.predict(X_test.values)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f'Pure Random Forest Regressor MSE: {mse_rf}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cisc7021",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
